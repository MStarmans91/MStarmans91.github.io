<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Martijn P.A. Starmans, PhD - PI AI for Integrated Diagnostics (AIID)</title>
    <link>https://MStarmans91.github.io/project/</link>
      <atom:link href="https://MStarmans91.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 02 Jun 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://MStarmans91.github.io/media/icon_hu08ff99a11f940ac4761bcab7c4c5c317_13983_512x512_fill_lanczos_center_3.png</url>
      <title>Projects</title>
      <link>https://MStarmans91.github.io/project/</link>
    </image>
    
    <item>
      <title>AI-Based Phenotyping of Soft Tissue Tumors from Histopathology Images</title>
      <link>https://MStarmans91.github.io/project/saipathomics/</link>
      <pubDate>Mon, 02 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://MStarmans91.github.io/project/saipathomics/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Soft tissue tumors are a heterogeneous group of mesenchymal neoplasms that vary widely in morphology, behavior, and clinical outcome. Accurate phenotyping from histopathology is essential for diagnosis and treatment but remains challenging due to their rarity and diversity. Moreover, current AI models in digital pathology are often trained on narrow disease-specific datasets, limiting their generalizability. There is growing interest in building large foundational models for computational pathology that can capture the spectrum of tumor morphology and be fine-tuned for downstream tasks such as grading, prognosis, or mutation prediction. This project aligns with that vision by focusing on phenotyping based on routine H&amp;amp;E-stained slides.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Aim&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The aim of this project is to contribute to the development of a deep learning model for broad phenotyping of soft tissue tumors. The student will work with high-resolution whole slide images, apply or adapt neural architectures for patch-level and slide-level analysis, and experiment with representation learning techniques. Depending on interest, the focus can be narrowed to a subtype (e.g., liposarcomas) or extended to multi-class classification and clustering of phenotypic patterns. The resulting model will form part of a larger framework that can later be fine-tuned for specific clinical outcomes, such as prognosis prediction or therapy response.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Related research:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://doi.org/10.1016/j.jpi.2024.100368&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.jpi.2024.100368&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://doi.org/10.1016/j.ajpath.2023.03.012&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.ajpath.2023.03.012&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Supervisors&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Karthik Prathaban&lt;/li&gt;
&lt;li&gt;Farhan Akram&lt;/li&gt;
&lt;li&gt;Martijn Starmans&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Feel free to mail me if you are interested in this project or want more information!&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Automated Deep Learning for Soft-Tissue Tumor Classification Using Meta-Learning and AutoML</title>
      <link>https://MStarmans91.github.io/project/automlmeta/</link>
      <pubDate>Mon, 02 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://MStarmans91.github.io/project/automlmeta/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;AI models in medical imaging are usually developed from scratch using disease-specific datasets. While this works for common diseases, it poses a major bottleneck for rare cancers like soft-tissue tumors (STTs), where labelled data is scarce. Unlike humans, who can learn new concepts from just a few examples by drawing on prior experience, current AI systems require large amounts of task-specific data due to how they are trained. This project addresses that limitation by combining meta-learning and automated machine learning (AutoML) to enable knowledge transfer across clinical and reducing reliance on large datasets.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Aim&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Aim The aim of this project is to develop a novel methodology that integrates automated machine learning and meta-learning for medical image classification. Instead of trial-and-error model design, we will automate model selection and tuning using prior experience on related tasks and datasets. By learning from previous clinical applications, the system will be able to generalize across different diseases and imaging modalities, particularly in the context of rare cancers where data is limited. The project will involve designing model search strategies, incorporating knowledge transfer mechanisms, and evaluating the approach on real-world clinical datasets. Note that this project is quite technical.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Related research:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hutter, F., Kotthoff, L., &amp;amp; Vanschoren, J. (Eds.). (2019). Automated machine learning: Methods, systems, challenges. Springer.&lt;/li&gt;
&lt;li&gt;Hospedales, T., Antoniou, A., Micaelli, P., &amp;amp; Storkey, A. (2021). Meta-learning in neural networks: A survey. IEEE transactions on pattern analysis and machine intelligence, 44(9), 5149-5169.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Supervisors&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Natalia Oviedo Acosta&lt;/li&gt;
&lt;li&gt;Stefan Klein&lt;/li&gt;
&lt;li&gt;Martijn Starmans&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Feel free to mail me if you are interested in this project or want more information!&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Benchmarking AutoML and Meta-Learning on Medical Image Classification</title>
      <link>https://MStarmans91.github.io/project/automlbenchmark/</link>
      <pubDate>Mon, 02 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://MStarmans91.github.io/project/automlbenchmark/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Medical image classification has advanced rapidly due to the availability of large pretrained models and foundation models. However, most model development workflows in medical imaging are still highly customized and dataset-specific, making it difficult to compare methods or reproduce results. This lack of standardization is especially limiting for techniques like automated machine learning (AutoML) and meta-learning, which aim to generalize across tasks and reduce manual effort. While generic AutoML benchmarks exist for natural images or tabular data, there is no established benchmark tailored to the unique characteristics of medical image data particularly in oncology. Creating such a benchmark would enable fair, systematic evaluation of AutoML and meta-learning approaches.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Aim&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This project aims to build a comprehensive and extensible benchmark for evaluating AutoML and meta-learning methods in medical image classification, with a particular emphasis on oncological tasks. It involves curating a diverse collection of publicly available medical imaging datasets, prioritizing cancer-related classification problems across modalities such as CT and MRI. In parallel, a portfolio of pretrained and foundation models—including resources such as SAM-Med3D [1], MONAI Model Zoo, and others—will be collected and structured into a unified, reusable model hub. Based on these components, the benchmark will support the systematic evaluation of AutoML and meta-learning frameworks, including methods like Quick-Tune [2] and DEHB [3]. Evaluations will focus on metrics such as classification accuracy, cross-dataset generalization, and computational efficiency. Note that this project is quite technical.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Related research:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Wang, S., Zhu, C., Lu, M. Y., Qian, Z., Chen, R. J., &amp;amp; Mahmood, F. (2023). SAM-Med3D: Segment Anything in 3D Images with Med3D Adapter. arXiv preprint arXiv:2308.16184.&lt;/li&gt;
&lt;li&gt;Arango, S. P., Ferreira, F., Kadra, A., Hutter, F., &amp;amp; Grabocka, J. (2023). Quick-tune: Quickly learning which pretrained model to finetune and how. arXiv preprint arXiv:2306.03828.&lt;/li&gt;
&lt;li&gt;Awad, N., Doerr, F., Müller, S., Benjamins, C., &amp;amp; Hutter, F. (2021). DEHB: Evolutionary Hyperband for Scalable, Robust and Efficient Hyperparameter Optimization. In Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (AISTATS), PMLR 130: 1344–1352.  &lt;a href=&#34;https://proceedings.mlr.press/v130/awad21a.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://proceedings.mlr.press/v130/awad21a.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Supervisors&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Natalia Oviedo Acosta&lt;/li&gt;
&lt;li&gt;Stefan Klein&lt;/li&gt;
&lt;li&gt;Martijn Starmans&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Feel free to mail me if you are interested in this project or want more information!&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Dynamic Preprocessing Pipeline for Soft Tissue Tumor Classification</title>
      <link>https://MStarmans91.github.io/project/preprocessing/</link>
      <pubDate>Mon, 02 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://MStarmans91.github.io/project/preprocessing/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In medical imaging, preprocessing steps like normalization, resampling, and cropping are often applied using fixed heuristics. While standard, these static methods can limit performance in complex settings such as soft tissue tumors (STTs), where anatomical variation and acquisition inconsistencies are common.  nnU-Net [1] has shown that task-specific, well-chosen preprocessing can strongly influence performance by adapting settings to the dataset characteristics. Building on this idea, and inspired by OBELISK-Net [2], which integrates preprocessing within the network as a learnable module, this project explores a dynamic alternative: making preprocessing fully differentiable and trainable alongside the model.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Aim&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The aim of this project is to build an adaptive preprocessing pipeline for medical imaging with a focus on STTs. Instead of using fixed rules for intensity normalization, voxel spacing resampling, or spatial cropping, the project will implement these steps as learnable layers in a deep neural network. These layers will be differentiable and trained end-to-end with the downstream model, allowing them to discover the most effective image transformations in a data-driven, task-specific way. The proposed pipeline will be compared with conventional preprocessing strategies and evaluated on public medical imaging datasets, especially for rare cancers such as STTs. Note that this project is quite technical.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Related research:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Isensee, F., Jaeger, P.F., Full, P.M., Vollmuth, P., Maier-Hein, K.H.: nnU-Net: A self-configuring method for deep learning-based biomedical image segmentation. Nature Methods 18, 203–211 (2021)&lt;/li&gt;
&lt;li&gt;Heinrich, M. P., Oktay, O., &amp;amp; Bouteldja, N. (2019). OBELISK-Net: Fewer layers to solve 3D multi-organ segmentation with sparse deformable convolutions. Medical image analysis, 54, 1-9.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Supervisors&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Natalia Oviedo Acosta&lt;/li&gt;
&lt;li&gt;Stefan Klein&lt;/li&gt;
&lt;li&gt;Martijn Starmans&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Feel free to mail me if you are interested in this project or want more information!&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>From Image to Insight; Can Vision Language Models see like Radiologists?</title>
      <link>https://MStarmans91.github.io/project/laichatgpt/</link>
      <pubDate>Mon, 02 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://MStarmans91.github.io/project/laichatgpt/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Diagnosing liver lesions using multiparametric MRI requires detecting complex, often subtle features - such as washout, fat content, capsular enhancement, and iron deposition - However, these features can be subtle and challenging to detect, often requiring the expertise of experienced radiologists, which limits the scalability of supervised AI approaches.&lt;/p&gt;
&lt;p&gt;With the rise of vision-language models (VLMs) like GPT-4V and DeepSeek-VL, a key question is whether such models can reliably identify and describe these features across diverse MRI sequences. This project explores the diagnostic potential of VLMs as assistive tools, with a particular focus on benchmarking their ability to &amp;ldquo;see&amp;rdquo; and reason over relevant imaging features in comparison to expert radiologist interpretations and pathology-confirmed diagnoses.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Aim&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The primary goal of this projectis to systematically evaluate how well these models extract and describe clinically meaningful features from annotated MRI data, and to what extent their predictions aligns with real-world diagnostic outcomes. Depending on results and interest, the project may also explore fine-tuning existing models to improve domain-specific performance, or - if performance proves reliable - developing a lightweight graphical interface to make these models more accessible and interpretable in a clinical context. This research is part of the Liver Artificial Intelligene - Consortium, a collaborative initiative focused on advancing AI models in liver imaging, bringing together interdisciplinary expertise to unlock new diagnostic possibilities.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Related research:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://doi.org/10.1016/j.jpi.2024.100368&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.jpi.2024.100368&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://doi.org/10.1016/j.ajpath.2023.03.012&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.ajpath.2023.03.012&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Supervisors&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Frederik Hartmann&lt;/li&gt;
&lt;li&gt;Ruben Niemantsverdriet&lt;/li&gt;
&lt;li&gt;Maarten Thomeer&lt;/li&gt;
&lt;li&gt;Stefan Klein&lt;/li&gt;
&lt;li&gt;Martijn Starmans&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Feel free to mail me if you are interested in this project or want more information!&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Predicting CTNNB1 S45F Mutation in Desmoid Tumors from H&amp;E-Stained Histopathology Images</title>
      <link>https://MStarmans91.github.io/project/desmoidpathomics/</link>
      <pubDate>Mon, 02 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://MStarmans91.github.io/project/desmoidpathomics/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Desmoid tumors are rare soft tissue neoplasms that exhibit local invasiveness without metastatic potential. A significant subset of sporadic desmoid tumors harbors activating mutations in the CTNNB1 gene, particularly the S45F mutation, which is associated with higher recurrence risk and poorer response to conservative therapies. Detecting this mutation currently requires molecular assays, which are costly and not always available in resource-limited settings. This project explores the potential of using deep learning to predict S45F mutation status directly from histology images, enabling a scalable screening alternative.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Aim&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;he aim of this project is to develop and validate a deep learning model that predicts the presence of the CTNNB1 S45F mutation in desmoid tumors from H&amp;amp;E-stained whole slide images. The model will be trained using annotated data with known mutation status and will explore image-based features that correlate with underlying molecular changes. The project will involve data preprocessing, model development (e.g., using convolutional neural networks or vision transformers), and evaluation of predictive performance. This work has the potential to improve personalized decision-making in desmoid tumor management.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Related research:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://doi.org/10.3389/fonc.2023.1206800&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.3389/fonc.2023.1206800&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://doi.org/10.1016/j.ejca.2024.114270&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1016/j.ejca.2024.114270&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Supervisors&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Karthik Prathaban&lt;/li&gt;
&lt;li&gt;Farhan Akram&lt;/li&gt;
&lt;li&gt;Martijn Starmans&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Feel free to mail me if you are interested in this project or want more information!&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
